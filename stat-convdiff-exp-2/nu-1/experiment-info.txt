stat_convdiff_6.py 

nu = dde.Variable(1.1)
nu_true = 1.0
a1 = 1.0
a2 = 3.0

Randbed:
1 + cos(2 pi x2) links fÃ¼r x2 < 0.5,
1 + cos(pi x1) unten,
0 Rest
-----------------------

num_domain=200,
num_boundary=50,
num_test = 1000 

net = dde.nn.FNN([2] + [40] * 4 + [1], "tanh", "Glorot uniform")
no weights                                        
100000 epochs                                                        
lr=0.0002                                                         

---------------------------
run1:

Best model at step 100000:
  train loss: 2.41e-03
  test loss: 2.48e-03
  test metric: []

'train' took 755.132330 s

l2 relative error for u: 0.041620951629448344

---------------------------
run2:

Best model at step 100000:
  train loss: 2.61e-03
  test loss: 2.12e-02
  test metric: []

'train' took 767.439257 s

l2 relative error for u: 0.04553181459037527

---------------------------
run3 - lr=0.001:

Best model at step 95000:
  train loss: 8.22e-04
  test loss: 8.33e-04
  test metric: []

'train' took 749.158333 s

l2 relative error for u: 0.04190503782278239

--------------------------
run4 - lr=0.001:

Best model at step 100000:
  train loss: 1.59e-03
  test loss: 1.52e-03
  test metric: []

'train' took 753.033246 s

l2 relative error for u: 0.04205335748071888

--------------------------
run5 - lr=0.001 + nu = dde.Variable(0.0):

Best model at step 87000:
  train loss: 1.18e-03
  test loss: 1.20e-03
  test metric: []

'train' took 768.376524 s

l2 relative error for u: 0.04091572565291207

--------------------------
run6 - lr=0.001 + nu = dde.Variable(0.0):

Best model at step 100000:
  train loss: 9.78e-04
  test loss: 1.00e-03
  test metric: []

'train' took 767.348157 s

l2 relative error for u: 0.04148019028027362